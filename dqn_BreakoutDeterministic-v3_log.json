{"episode_reward": [-2.0], "nb_steps": [248], "mean_absolute_error": [NaN], "loss": [NaN], "mean_eps": [NaN], "nb_episode_steps": [248], "duration": [222.185124874115], "episode": [0], "mean_q": [NaN]}