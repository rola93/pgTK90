{"episode_reward": [-2.0], "nb_steps": [248], "mean_absolute_error": [NaN], "loss": [NaN], "mean_eps": [NaN], "nb_episode_steps": [248], "duration": [225.29031205177307], "episode": [0], "mean_q": [NaN]}