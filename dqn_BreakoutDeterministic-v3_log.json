{"episode_reward": [-1.0, -1.0, -1.0, -1.0], "nb_steps": [28, 71, 145, 215], "mean_absolute_error": [NaN, NaN, 0.14844951609318907, 0.4762336471501519], "loss": [NaN, NaN, 0.01827055173502727, 0.02492200009360471], "mean_eps": [NaN, NaN, 0.9998884000000001, 0.999838], "nb_episode_steps": [28, 43, 74, 70], "duration": [14.99294900894165, 20.22089385986328, 52.54489994049072, 45.301705837249756], "episode": [0, 1, 2, 3], "mean_q": [NaN, NaN, 0.2174685759977861, 0.6337592742022347]}